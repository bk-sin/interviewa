import { Text, ThemedView } from "@/src/shared";
import { fontSizes, spacing, theme } from "@/src/theme";
import MaterialIcons from "@expo/vector-icons/MaterialIcons";
import { Audio } from "expo-av";
import React, { useEffect, useRef, useState } from "react";
import { Animated, StyleSheet, View } from "react-native";
import { Footer, InterviewHeaderContainer } from "../components";
import { AudioBar } from "../components/audio-bar";

// Importaci√≥n condicional de expo-speech-recognition
let ExpoSpeechRecognitionModule: any = null;
let useSpeechRecognitionEvent: any = null;

try {
  // eslint-disable-next-line @typescript-eslint/no-require-imports
  const speechRecognition = require("expo-speech-recognition");
  ExpoSpeechRecognitionModule = speechRecognition.ExpoSpeechRecognitionModule;
  useSpeechRecognitionEvent = speechRecognition.useSpeechRecognitionEvent;
} catch {
  console.warn("‚ö†Ô∏è expo-speech-recognition no disponible en Expo Go");
  console.warn("üì± Para transcripci√≥n, ejecuta: npx expo run:android");
}

export default function InterviewScreen() {
  // ========================================
  // CONFIGURACI√ìN DE SENSIBILIDAD DEL AUDIO
  // ========================================
  const AUDIO_CONFIG = {
    // Rango de decibelios a considerar
    minDb: -60, // M√°s alto = m√°s sensible (ej: -40), m√°s bajo = menos sensible (ej: -60)

    // Curva de respuesta (exponente)
    volumeCurve: 1.5, // M√°s alto = m√°s dram√°tico (ej: 2.0), m√°s bajo = m√°s lineal (ej: 1.0)

    // Multiplicadores por frecuencia (cu√°nto se amplifican)
    bassMultiplier: 1.3, // Graves: Reducido de 1.5 a 1.3 para transici√≥n m√°s suave
    midMultiplier: 1.2, // Medias: 1.2x
    trebleMultiplier: 1.4, // Agudas: 1.4x m√°s grande con volumen medio

    // Umbral de activaci√≥n (0-1)
    bassThreshold: 0.3, // Graves: Reducido de 0.4 a 0.3 para activaci√≥n m√°s temprana y gradual
    trebleThreshold: 0.6, // Agudas se activan cuando volumen < 0.6

    // Reducci√≥n cuando no est√°n activas
    bassInactive: 0.4, // Graves: Aumentado de 0.2 a 0.4 para menor contraste
    trebleInactive: 0.3, // Agudas cuando el volumen es muy alto

    // Velocidad de animaci√≥n (ms)
    animationDuration: 60, // M√°s bajo = m√°s r√°pido (ej: 40), m√°s alto = m√°s suave (ej: 100)
  };

  // 1. TRES referencias de animaci√≥n: una por rango de frecuencia
  const bassVolumeAnim = useRef(new Animated.Value(0)).current; // Graves (0-250Hz)
  const midVolumeAnim = useRef(new Animated.Value(0)).current; // Medias (250Hz-4kHz)
  const trebleVolumeAnim = useRef(new Animated.Value(0)).current; // Agudas (4kHz+)

  // Usamos una ref para la grabaci√≥n activa para poder limpiarla al salir
  const recordingInstanceRef = useRef<Audio.Recording | null>(null);

  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState<string>("");
  const [permissionResponse, requestPermission] = Audio.usePermissions();
  const [isSpeechRecognitionAvailable] = useState(
    ExpoSpeechRecognitionModule !== null && useSpeechRecognitionEvent !== null
  );

  const waveformBase = [
    16, 32, 24, 48, 80, 40, 112, 64, 128, 96, 144, 80, 112, 56, 96, 32, 48, 20,
    36, 16,
  ];

  // ========================================
  // CONFIGURACI√ìN DE SPEECH RECOGNITION
  // ========================================
  // Solo configurar eventos si el m√≥dulo est√° disponible
  if (useSpeechRecognitionEvent) {
    // eslint-disable-next-line react-hooks/rules-of-hooks
    useSpeechRecognitionEvent("start", () => {
      console.log("üé§ Speech recognition started");
    });

    // eslint-disable-next-line react-hooks/rules-of-hooks
    useSpeechRecognitionEvent("end", () => {
      console.log("üõë Speech recognition ended");
    });

    // eslint-disable-next-line react-hooks/rules-of-hooks
    useSpeechRecognitionEvent("result", (event: any) => {
      console.log("üìù Result:", event.results[0]?.transcript);
      setTranscript(event.results[0]?.transcript || "");
    });

    // eslint-disable-next-line react-hooks/rules-of-hooks
    useSpeechRecognitionEvent("error", (event: any) => {
      console.error("‚ùå Speech recognition error:", event.error, event.message);
    });
  }

  async function startRecording() {
    try {
      if (permissionResponse?.status !== "granted") {
        const perm = await requestPermission();
        if (!perm.granted) return;
      }

      // Solicitar permisos de speech recognition (solo si est√° disponible)
      if (ExpoSpeechRecognitionModule && isSpeechRecognitionAvailable) {
        try {
          const speechPermission =
            await ExpoSpeechRecognitionModule.requestPermissionsAsync();

          if (!speechPermission.granted) {
            console.warn("‚ö†Ô∏è Permisos de reconocimiento de voz no otorgados");
          } else {
            // Iniciar reconocimiento de voz
            ExpoSpeechRecognitionModule.start({
              lang: "es-AR",
              interimResults: true,
              continuous: true,
              maxAlternatives: 1,
            });
          }
        } catch (speechError) {
          console.warn(
            "‚ö†Ô∏è No se pudo iniciar speech recognition:",
            speechError
          );
        }
      } else {
        console.log("üìù Speech recognition no disponible, solo grabando audio");
      }

      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      const { recording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY,
        (status) => {
          if (status.isRecording) {
            const metering = status.metering || -100;

            // F√≠sica de volumen usando configuraci√≥n
            const dbRange = Math.max(metering, AUDIO_CONFIG.minDb);

            // Convertimos a 0-1
            let normalizedVolume =
              (dbRange - AUDIO_CONFIG.minDb) / (0 - AUDIO_CONFIG.minDb);

            // Aplicamos la curva de respuesta configurada
            normalizedVolume = Math.pow(
              normalizedVolume,
              AUDIO_CONFIG.volumeCurve
            );

            // SIMULACI√ìN DE FRECUENCIAS SEPARADAS usando configuraci√≥n

            // Graves (Izquierda): Transici√≥n gradual en lugar de abrupta
            // Usamos una curva suave que empieza antes pero crece progresivamente
            const bassProgress = Math.max(
              0,
              (normalizedVolume - AUDIO_CONFIG.bassThreshold) /
                (1 - AUDIO_CONFIG.bassThreshold)
            );
            const bassIntensity =
              AUDIO_CONFIG.bassInactive * normalizedVolume +
              bassProgress *
                (AUDIO_CONFIG.bassMultiplier - AUDIO_CONFIG.bassInactive) *
                normalizedVolume;

            // Medias (Centro): Responden uniformemente con multiplicador
            const midIntensity = normalizedVolume * AUDIO_CONFIG.midMultiplier;

            // Agudas (Derecha): Tambi√©n con transici√≥n gradual
            const trebleProgress = Math.max(
              0,
              (AUDIO_CONFIG.trebleThreshold - normalizedVolume) /
                AUDIO_CONFIG.trebleThreshold
            );
            const trebleIntensity =
              AUDIO_CONFIG.trebleInactive * normalizedVolume +
              trebleProgress *
                (AUDIO_CONFIG.trebleMultiplier - AUDIO_CONFIG.trebleInactive) *
                normalizedVolume;

            // Animamos con la duraci√≥n configurada
            Animated.parallel([
              Animated.timing(bassVolumeAnim, {
                toValue: bassIntensity,
                duration: AUDIO_CONFIG.animationDuration,
                useNativeDriver: false,
              }),
              Animated.timing(midVolumeAnim, {
                toValue: midIntensity,
                duration: AUDIO_CONFIG.animationDuration,
                useNativeDriver: false,
              }),
              Animated.timing(trebleVolumeAnim, {
                toValue: trebleIntensity,
                duration: AUDIO_CONFIG.animationDuration,
                useNativeDriver: false,
              }),
            ]).start();
          }
        },
        100
      );

      // Guardamos la instancia en la Ref y en el Estado
      recordingInstanceRef.current = recording;
      setIsRecording(true);
      console.log("Grabaci√≥n iniciada");
    } catch (err) {
      console.error("Error al iniciar grabaci√≥n", err);
    }
  }

  async function stopRecording() {
    // Verificamos la referencia, no solo el estado
    if (!recordingInstanceRef.current) return;

    console.log("Deteniendo grabaci√≥n...");

    try {
      // Detener speech recognition (solo si est√° disponible)
      if (ExpoSpeechRecognitionModule && isSpeechRecognitionAvailable) {
        try {
          ExpoSpeechRecognitionModule.stop();
        } catch (speechError) {
          console.warn("‚ö†Ô∏è Error al detener speech recognition:", speechError);
        }
      }

      await recordingInstanceRef.current.stopAndUnloadAsync();
      const uri = recordingInstanceRef.current.getURI();
      console.log("Grabaci√≥n guardada en:", uri);

      // Animamos todas las barras a su estado m√°s bajo
      Animated.parallel([
        Animated.timing(bassVolumeAnim, {
          toValue: 0,
          duration: 300,
          useNativeDriver: false,
        }),
        Animated.timing(midVolumeAnim, {
          toValue: 0,
          duration: 300,
          useNativeDriver: false,
        }),
        Animated.timing(trebleVolumeAnim, {
          toValue: 0,
          duration: 300,
          useNativeDriver: false,
        }),
      ]).start();

      // Limpiamos referencias
      recordingInstanceRef.current = null;
      setIsRecording(false);
    } catch (error) {
      console.log("Error al detener", error);
    }
  }

  useEffect(() => {
    startRecording();

    // Cleanup function: Se ejecuta si el componente se desmonta
    return () => {
      if (recordingInstanceRef.current) {
        stopRecording();
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  return (
    <ThemedView style={styles.container}>
      <InterviewHeaderContainer />

      <View style={styles.mainContent}>
        <View style={styles.questionContainer}>
          <Text style={styles.questionTitle}>
            Contame de un conflicto que tuviste que resolver en tu equipo.
          </Text>
          <Text style={styles.questionDescription}>
            Pod√©s describir la situaci√≥n, las acciones que tomaste y cu√°l fue el
            resultado.
          </Text>

          <View style={styles.timerContainer}>
            <MaterialIcons
              name="timer"
              size={20}
              color={theme.colors.primary}
              style={styles.timerIcon}
            />
            <Text style={styles.timerText}>Recomendado: 60‚Äì90 segundos</Text>
          </View>
        </View>

        <View style={styles.waveformContainer}>
          <View style={styles.waveformRow}>
            {waveformBase.map((height, idx) => (
              <AudioBar
                key={idx}
                index={idx}
                totalBars={waveformBase.length}
                baseHeight={height}
                bassVolumeAnim={bassVolumeAnim}
                midVolumeAnim={midVolumeAnim}
                trebleVolumeAnim={trebleVolumeAnim}
              />
            ))}
          </View>

          {/* Transcripci√≥n en tiempo real */}
          {transcript && (
            <View style={styles.transcriptionContainer}>
              <Text style={styles.transcriptionLabel}>Transcripci√≥n:</Text>
              <Text style={styles.transcriptionText}>
                {transcript}
              </Text>
            </View>
          )}
        </View>
      </View>

      <Footer
        buttons={[
          {
            label: isRecording ? "Detener" : "Repetir", // Cambia etiqueta seg√∫n estado
            onPress: isRecording ? stopRecording : () => startRecording(),
            leftIcon: isRecording ? "stop" : "replay",
            variant: "secondary",
          },
          {
            label: "Siguiente",
            onPress: () => {},
            variant: "secondary",
            disabled: true,
          },
        ]}
        layout="row"
      />
    </ThemedView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    // Aseg√∫rate de que theme.colors.background.dark exista, si no usa '#10221c'
    backgroundColor: theme.colors.background?.dark || "#10221c",
  },
  mainContent: {
    flex: 1,
    padding: theme.spacing.lg,
  },
  questionContainer: {
    marginBottom: theme.spacing.xl,
    alignItems: "center",
  },
  questionTitle: {
    ...theme.typography.h3,
    color: theme.colors.text.primary,
    textAlign: "center",
    marginBottom: theme.spacing.md,
  },
  questionDescription: {
    ...theme.typography.body,
    color: theme.colors.text.muted,
    textAlign: "center",
    lineHeight: 24,
  },
  timerContainer: {
    marginTop: theme.spacing.lg,
    flexDirection: "row",
    alignItems: "center",
    gap: theme.spacing.xs,
  },
  timerIcon: {
    opacity: 0.8,
  },
  timerText: {
    ...theme.typography.bodySmall,
    fontSize: fontSizes.xs,
    color: theme.colors.primary,
    fontWeight: "500",
    opacity: 0.8,
  },
  waveformContainer: {
    flex: 1,
    alignItems: "center",
    justifyContent: "center", // A√±adido para centrar verticalmente
    width: "100%",
    paddingHorizontal: 20,
    paddingBottom: spacing["5xl"],
  },
  waveformRow: {
    height: 200, // Altura fija para contener la animaci√≥n
    flexDirection: "row",
    alignItems: "center",
    justifyContent: "center", // Centrar barras horizontalmente
  },
  transcriptionContainer: {
    marginTop: theme.spacing.xl,
    padding: theme.spacing.md,
    backgroundColor: theme.rgba(theme.colors.background.card, 0.3),
    borderRadius: theme.borderRadius.base,
    width: "100%",
  },
  transcriptionLabel: {
    ...theme.typography.bodySmall,
    color: theme.colors.primary,
    marginBottom: theme.spacing.xs,
    fontWeight: "600",
  },
  transcriptionText: {
    ...theme.typography.body,
    color: theme.colors.text.primary,
    lineHeight: 24,
  },
});
